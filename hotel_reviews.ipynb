{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "n-gum3E6ujxe",
    "outputId": "269efc0d-61e5-4d54-ec45-bcbad29a59b5"
   },
   "source": [
    "# Hotel Reviews- Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQfJztJau_4j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import spacy\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gBuR-Geve5g"
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel('hotel_reviews (1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VRqX1yRWwsim",
    "outputId": "70a07c05-cab2-48ac-e5f3-4f982669644e"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7FqV9c3xHp3",
    "outputId": "4d52b972-1597-418c-b7a3-b383f3f84e7e"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tthVsauWxLGI",
    "outputId": "a275eff8-fd50-4b0d-f7ba-433387e5e9bd"
   },
   "outputs": [],
   "source": [
    "data.info()     # no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dz6BpaPcxNID"
   },
   "outputs": [],
   "source": [
    "# removing trailing and leading characters\n",
    "data=[Review.strip() for Review in data.Review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_V5dK4Fxsi0n",
    "outputId": "b01ed059-107f-4a35-d3b2-467b03ae78bf"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ilcg_NouripF"
   },
   "outputs": [],
   "source": [
    "# removing empty strings\n",
    "data=[Review for Review in data if Review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7SkckOJtIWD",
    "outputId": "57aa4a42-24b6-4263-a2ce-fbb4a6da3f23"
   },
   "outputs": [],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "STTRm_3EtLod",
    "outputId": "ae5f9d7b-73f8-499a-f5e2-f15192e5ac55"
   },
   "outputs": [],
   "source": [
    "# joining list into 1 string\n",
    "text=' '.join(data)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4mIUIZ3tfor",
    "outputId": "80b2b1c7-6010-4f91-e1b9-8ff1af8f1140"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "DREbJyhavD11",
    "outputId": "2bcd55c8-2db9-476d-dbe0-53398a8bba97"
   },
   "outputs": [],
   "source": [
    "# removing punctuations\n",
    "import string\n",
    "no_punc_text=text.translate(str.maketrans('','',string.punctuation))\n",
    "no_punc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpwFpgm1u4ds",
    "outputId": "aee4d457-1e92-4ae2-d053-3aad73d15085"
   },
   "outputs": [],
   "source": [
    "# tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "text_tokens=word_tokenize(no_punc_text)\n",
    "print(text_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fejaCKywCMl",
    "outputId": "a0422730-17fb-435b-d07a-53f77c0f5699"
   },
   "outputs": [],
   "source": [
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6ngySJAwGee",
    "outputId": "6ed98fa2-0fef-4b96-c732-b6c96e88d3d3"
   },
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zt2HiF6w_Fj"
   },
   "outputs": [],
   "source": [
    "my_stop_words=stopwords.words('english')\n",
    "\n",
    "sw_list = ['hotel','monaco','seattle']\n",
    "my_stop_words.extend(sw_list)\n",
    "\n",
    "no_stop_tokens=[word for word in text_tokens if not word in my_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TjkoXq4z0OK",
    "outputId": "caeccbdd-9c51-4e47-b134-08f0c8b363a9"
   },
   "outputs": [],
   "source": [
    "print(no_stop_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "dct=Counter(no_stop_tokens) \n",
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_occur=dct.most_common(10) \n",
    "print(most_occur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZN5RDECZINZW",
    "outputId": "fba5d8b0-5af0-4dc6-9de7-bb397323f6d1"
   },
   "outputs": [],
   "source": [
    "# normalizing data\n",
    "lower_words=[Review.lower() for Review in no_stop_tokens]\n",
    "print(lower_words[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yfdpQNBN0Ci",
    "outputId": "abf94e8d-84f3-4d1b-9218-e1e425a0e908"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps= PorterStemmer()\n",
    "stemmed_tokens=[ps.stem(word) for word in lower_words]\n",
    "print(stemmed_tokens[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens=[lemmatizer.lemmatize(word) for word in lower_words]\n",
    "print(lemmatized_tokens[0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "0osBb0gZOTxt",
    "outputId": "d316a09b-24a4-493e-dfdd-2a71e2976dc2"
   },
   "outputs": [],
   "source": [
    "clean_text=' '.join(lemmatized_tokens)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KJ9I56jP1lI"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0rYMbulQ11D"
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "text_cv=cv.fit_transform(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQ19zUhnT6PT",
    "outputId": "4b8c9e63-3e88-4f23-ac83-1a6b204cfa2a"
   },
   "outputs": [],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAmS0QsIT_oF",
    "outputId": "2764b835-e229-4448-c6e3-5189a46ff431"
   },
   "outputs": [],
   "source": [
    "print(cv.get_feature_names_out()[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hioVTKoTUvlb"
   },
   "outputs": [],
   "source": [
    "# Count Vectorizer with N-grams ( Bigrams & Trigrams)\n",
    "cv_ngram_range=CountVectorizer(analyzer='word',ngram_range=(1,3),max_features=100)\n",
    "bow_matrix_ngram=cv_ngram_range.fit_transform(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcpkYRzzU6YW",
    "outputId": "74618d40-1aaf-4a8b-a673-fa4c433ef563"
   },
   "outputs": [],
   "source": [
    "print(cv_ngram_range.get_feature_names_out())\n",
    "print(bow_matrix_ngram.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NcJijRBVD_n"
   },
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidfv_ngram_max_features=TfidfVectorizer(norm='l2',analyzer='word',ngram_range=(1,3),max_features=500)\n",
    "tfidf_matix_ngram=tfidfv_ngram_max_features.fit_transform(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XaFGOmeVJ7m",
    "outputId": "2ed063da-60e1-46ea-817d-de9b7580ee4d"
   },
   "outputs": [],
   "source": [
    "print(tfidfv_ngram_max_features.get_feature_names_out())\n",
    "print(tfidf_matix_ngram.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "id": "ixBUkBxXVUxq",
    "outputId": "feb287d8-20bd-45cf-b734-3851f69db863"
   },
   "outputs": [],
   "source": [
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(40,30))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Generate Word Cloud\n",
    "STOPWORDS.add('resort')\n",
    "STOPWORDS.add('room')\n",
    "STOPWORDS.add('said')\n",
    "STOPWORDS.add('say')\n",
    "STOPWORDS.add('nt')\n",
    "STOPWORDS.add('going')\n",
    "STOPWORDS.add('time')\n",
    "STOPWORDS.add('really')\n",
    "STOPWORDS.add('used')\n",
    "STOPWORDS.add('went')\n",
    "STOPWORDS.add('asked')\n",
    "STOPWORDS.add('day')\n",
    "\n",
    "wordcloud=WordCloud(width=3000,height=2000,background_color='black',max_words=80,\n",
    "                   colormap='Set1',stopwords=STOPWORDS).generate(clean_text)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ3-DKe3VnE4"
   },
   "source": [
    "## NER- Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts Of Speech (POS) Tagging\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents     #Display all entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in doc.ents:\n",
    "    print(i, '|' , i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy library is not 100% precise\n",
    "#to display graphical representation for tags\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data1.iterrows():\n",
    "    review_text = row[0]\n",
    "    doc = nlp(review_text)\n",
    "    # Display named entities for each review\n",
    "    print(f\"Entities for Review {index + 1}:\")\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, '|', ent.label_)\n",
    "\n",
    "    # Display graphical representation for named entities\n",
    "    displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re=pd.read_excel('hotel_reviews (1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sampling positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_neg = data_re.loc[data_re[\"Rating\"]<3]\n",
    "data_neg = data_neg.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_five = data_re.loc[data_re['Rating'] == 5]\n",
    "data_five = data_five.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data_five.loc[:len(data_neg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([data_neg,data_pos], axis = 0)\n",
    "data_all = data_all.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[\"Sentiment\"]=np.where(data_all[\"Rating\"] == 5, \"Positive\" , \"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all= data_all.sample(frac=1)\n",
    "data_all= data_all.reset_index(drop = True)\n",
    "data_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_all.Review, data_all.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=CountVectorizer()\n",
    "x_train_vec = v.fit_transform(x_train)\n",
    "x_test_vec = v.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVM =svm.SVC(kernel = \"linear\")\n",
    "SVM.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score=SVM.score(x_test_vec, y_test)\n",
    "svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_svm = f1_score(y_test,SVM.predict(x_test_vec), average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = [\"unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown shopping area, pet friendly room showed no signs animal hair smells, monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy, goldfish named brandi enjoyed, did n't partake free wine coffee/tea service lobby thought great feature, great staff friendly, free wireless internet hotel worked suite 2 laptops, decor lovely eclectic mix pattens color palatte, animal print bathrobes feel like rock stars, nice did n't look like sterile chain hotel hotel personality excellent stay.\"]\n",
    "review1_vec = v.transform(review1)\n",
    "SVM.predict(review1_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = [\"stay did not care hotel, expecting cozy trendy room sadly disappointed tiny run-down room strange odor, bed practically floor level afraid head pillow, no warmth room just bare necessities, feel better place money not mention 30.00 mandatory valet parking,  \"]\n",
    "review2_vec = v.transform(review2)\n",
    "SVM.predict(review2_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review3 = [\"good place  \"]\n",
    "review3_vec = v.transform(review3)\n",
    "SVM.predict(review3_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Build the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(x_train_vec, y_train)\n",
    "\n",
    "# Predict sentiment labels on the testing set\n",
    "y_pred = nb_classifier.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "naivebayes_score = accuracy_score(y_test, y_pred)\n",
    "naivebayes_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb_classifier.predict(review1_vec))\n",
    "print(nb_classifier.predict(review2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb_classifier.predict(review3_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train_vec, y_train)\n",
    "y_pred = rf_classifier.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "randomforest_score = accuracy_score(y_test, y_pred)\n",
    "randomforest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_classifier.predict(review1_vec))\n",
    "print(rf_classifier.predict(review2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_classifier.predict(review3_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(x_train_vec, y_train)\n",
    "\n",
    "y_pred = logreg_model.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "logisticreg_score = accuracy_score(y_test, y_pred)\n",
    "logisticreg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg_model.predict(review1_vec))\n",
    "print(logreg_model.predict(review2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg_model.predict(review3_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "gb_classifier.fit(x_train_vec, y_train)\n",
    "\n",
    "y_pred = gb_classifier.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "gradientboosting_score = accuracy_score(y_test, y_pred)\n",
    "gradientboosting_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_classifier.predict(review1_vec))\n",
    "print(gb_classifier.predict(review2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_classifier.predict(review3_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "knn_classifier.fit(x_train_vec, y_train)\n",
    "\n",
    "# Predict sentiment labels on the testing set\n",
    "y_pred = knn_classifier.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "knn_score = accuracy_score(y_test, y_pred)\n",
    "knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_classifier.predict(review1_vec))\n",
    "print(knn_classifier.predict(review2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_classifier.predict(review3_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsummary_data= [['SVM', svm_score*100],\n",
    "         ['Random Forest', randomforest_score*100],\n",
    "          ['Logistic Regression', logisticreg_score*100],\n",
    "        ['Gradient Boosting', gradientboosting_score*100],\n",
    "        ['K Nearest Neighnours', knn_score*100]  ]\n",
    "\n",
    "\n",
    "df_model_summary= pd.DataFrame(modelsummary_data, columns=['Model', 'Accuracy'])\n",
    "\n",
    "\n",
    "print(df_model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsummary=df_model_summary.sort_values(by=['Accuracy'], ascending=False)\n",
    "modelsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsummary.plot.bar(x='Model', y='Accuracy')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
